{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMNN/zyjcE7AlTEhkNQFiGf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chandana909/AIMLprogram-iiith/blob/main/AIML_Module_1_Lab_2_Machine_Learning_terms_and_metrics_%26_Data_Augmentation_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Assuming all data is already split into alltraindata, alltrainlabel, and testdata, testlabel\n",
        "\n",
        "def average_accuracy_with_split(alldata, alllabel, splitpercentages, classifier, iterations=5):\n",
        "    results = []\n",
        "\n",
        "    for split in splitpercentages:\n",
        "        avg_accuracy = AverageAccuracy(alldata, alllabel, split, iterations, classifier)\n",
        "        results.append(avg_accuracy * 100)  # Convert to percentage\n",
        "\n",
        "    return results\n",
        "\n",
        "# Define percentages and classifiers for experiment\n",
        "split_percentages = [0.001, 0.01, 0.1, 0.2, 0.5, 0.8, 0.999]\n",
        "classifiers = {\n",
        "    \"1-Nearest Neighbor\": NN,\n",
        "    \"Random Classifier\": RandomClassifier\n",
        "}\n",
        "\n",
        "# Run the experiment\n",
        "results = {}\n",
        "for name, clf in classifiers.items():\n",
        "    results[name] = average_accuracy_with_split(alltraindata, alltrainlabel, split_percentages, clf)\n",
        "\n",
        "# Plotting the results\n",
        "for name, acc in results.items():\n",
        "    plt.plot(split_percentages, acc, label=name)\n",
        "\n",
        "plt.xlabel(\"Validation Set Percentage\")\n",
        "plt.ylabel(\"Average Validation Accuracy (%)\")\n",
        "plt.title(\"Effect of Validation Set Percentage on Accuracy\")\n",
        "plt.legend()\n",
        "plt.xscale(\"log\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VN3NvsZDSeyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming traindata, trainlabel, testdata, and testlabel are already defined and prepared\n",
        "\n",
        "# Implementing 1-NN\n",
        "knn_1 = KNeighborsClassifier(n_neighbors=1)\n",
        "knn_1.fit(traindata, trainlabel)\n",
        "pred_1nn = knn_1.predict(testdata)\n",
        "accuracy_1nn = accuracy_score(testlabel, pred_1nn) * 100\n",
        "print(\"Test accuracy using 1-Nearest Neighbor:\", accuracy_1nn, \"%\")\n",
        "\n",
        "# Implementing 3-NN\n",
        "knn_3 = KNeighborsClassifier(n_neighbors=3)\n",
        "knn_3.fit(traindata, trainlabel)\n",
        "pred_3nn = knn_3.predict(testdata)\n",
        "accuracy_3nn = accuracy_score(testlabel, pred_3nn) * 100\n",
        "print(\"Test accuracy using 3-Nearest Neighbor:\", accuracy_3nn, \"%\")\n"
      ],
      "metadata": {
        "id": "QWOdZTKCSevo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Effect of Split Size:\n",
        "\n",
        "Smaller Training Set (e.g., 50-60%): Accuracy drops for both 1-NN and 3-NN due to limited training data.\n",
        "Larger Training Set (e.g., 75-90%): Accuracy improves, with 3-NN performing slightly better due to reduced sensitivity to outliers.\n",
        "Extreme Splits (e.g., 0.1% or 99.9%): Inconsistent accuracy due to insufficient validation or training data.\n",
        "Comparison of 1-NN and 3-NN:\n",
        "\n",
        "1-NN: More sensitive to outliers, leading to less consistent results.\n",
        "3-NN: More stable and accurate with larger training data, less affected by single outliers.\n",
        "Effect of Averaging Across Splits:\n",
        "\n",
        "Improves accuracy consistency, especially for 3-NN. Higher iterations yield better accuracy estimates.\n",
        "Recommended Split:\n",
        "\n",
        "75-80% for training and 20-25% for validation provides a good balance for reliable accuracy estimation on test data."
      ],
      "metadata": {
        "id": "dMzYZmCDTdQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# Load and normalize the dataset\n",
        "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
        "train_X = train_X / 255.0\n",
        "test_X = test_X / 255.0\n",
        "\n",
        "# Function to get 50 images of each digit\n",
        "def get_subset(train_X, train_y, num_samples=50):\n",
        "    subset_X, subset_y = [], []\n",
        "\n",
        "    for digit in range(10):\n",
        "        indices = np.where(train_y == digit)[0]\n",
        "        selected_indices = np.random.choice(indices, num_samples, replace=False)\n",
        "        subset_X.append(train_X[selected_indices])\n",
        "        subset_y.append(train_y[selected_indices])\n",
        "\n",
        "    return np.concatenate(subset_X), np.concatenate(subset_y)\n",
        "\n",
        "# Get the subset of 50 images per digit\n",
        "subset_X, subset_y = get_subset(train_X, train_y)\n",
        "\n",
        "# Flatten the images\n",
        "subset_X = subset_X.reshape(-1, 28 * 28)\n",
        "\n",
        "# Nearest Neighbor Classifier\n",
        "def NN(train_data, train_labels, test_data):\n",
        "    test_data = test_data.reshape(-1, 28 * 28)\n",
        "    predictions = []\n",
        "\n",
        "    for query in test_data:\n",
        "        distances = np.sum((train_data - query) ** 2, axis=1)\n",
        "        nearest_index = np.argmin(distances)\n",
        "        predictions.append(train_labels[nearest_index])\n",
        "\n",
        "    return np.array(predictions)\n",
        "\n",
        "# Evaluate performance on the test set\n",
        "test_X_flat = test_X.reshape(-1, 28 * 28)\n",
        "test_predictions = NN(subset_X, subset_y, test_X_flat)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = np.mean(test_predictions == test_y)\n",
        "print(f\"Test accuracy with 50 images per digit: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "dHuSpi7lSetK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nuXP8zbVSeqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wTGInGDHSeoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mRerJW-FSelh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EDPILp4ASei3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YSahw5mcSegc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UmuKd39jSeds"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}